from sentence_transformers import SentenceTransformer
import numpy as np
import faiss

# åŠ è½½æ¨¡å‹ & FAISS ç´¢å¼•
model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
index = faiss.read_index("faiss.index")

# è¯»å–æ–‡æœ¬å—
with open("text_chunks.txt", "r", encoding="utf-8") as f:
    text_chunks = f.read().split("\n====\n")  # æŒ‰ "====" è¿›è¡Œåˆ†å‰²

# ç”¨æˆ·è¾“å…¥æŸ¥è¯¢
query_text = input("è¯·è¾“å…¥æŸ¥è¯¢æ–‡æœ¬ï¼š")
query_vector = model.encode([query_text])

# FAISS æœç´¢
k = 3  # è¿”å›æœ€ç›¸ä¼¼çš„ 3 ä¸ªæ–‡æœ¬å—
distances, indices = index.search(query_vector, k)

# è¾“å‡ºæŸ¥è¯¢ç»“æœ
print("\nğŸ” æŸ¥è¯¢ç»“æœï¼š")
for i, idx in enumerate(indices[0]):
    print(f"\nç›¸ä¼¼åº¦æ’å {i+1}ï¼š")
    print(text_chunks[idx])
    print(f"ğŸ”¹ ç›¸ä¼¼åº¦ï¼ˆL2 è·ç¦»ï¼‰ï¼š{distances[0][i]}")
    print("-" * 40)
